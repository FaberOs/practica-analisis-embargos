# Informe T√©cnico del Sistema de Reporter√≠a y An√°lisis Predictivo de Embargos Bancarios

## 1. Contexto y prop√≥sito del proyecto

El proyecto **"Sistema de An√°lisis Predictivo de Embargos Bancarios"** constituye una soluci√≥n integral de reporter√≠a automatizada e inteligencia artificial dise√±ada para entidades financieras que gestionan vol√∫menes significativos de embargos judiciales y coactivos. Surge como respuesta a tres desaf√≠os operativos cr√≠ticos identificados: la dispersi√≥n y heterogeneidad de datos (m√∫ltiples CSV sin normalizaci√≥n), la carencia de capacidad predictiva para planificar recursos, y limitaciones en visualizaci√≥n ejecutiva (reportes est√°ticos sin exploraci√≥n interactiva).

El objetivo del proyecto es triple:

1. **Automatizar la consolidaci√≥n de datos** mediante pipelines que reparan inconsistencias estructurales, normalizan categor√≠as e imputan valores, generando un dataset unificado (`embargos_consolidado_mensual.csv`).
2. **Integrar modelos de Machine Learning** que generen pron√≥sticos mensuales extendidos (12 meses con intervalos de confianza), regresi√≥n XGBoost para oficios/demandados, y clasificadores supervisados con filtrado por soporte m√≠nimo (‚â•100 muestras) para garantizar m√©tricas confiables.
3. **Proveer interfaces de reporter√≠a avanzadas** con dashboards Streamlit que visualicen hist√≥ricos, predicciones futuras, validaci√≥n hist√≥rica (comparaci√≥n real vs predicho), m√©tricas de calidad (precisi√≥n, recall, F1, matrices de confusi√≥n deserializadas) y capacidades de exportaci√≥n.

La soluci√≥n se distribuye como ejecutable Windows autocontenido (PyInstaller + Inno Setup), permitiendo adopci√≥n sin dependencias t√©cnicas.

**Documentaci√≥n t√©cnica complementaria**: el proyecto incluye informes especializados en `INFORME_VALIDACION_MODELO_ML.md` (pipeline predictivo), `INFORME_VALIDACION_DASHBOARD_EMBARGOS.md` (dashboard exploratorio) e `INFORME_VALIDACION_DASHBOARD_PREDICCIONES.md` (dashboard de pron√≥sticos), todos adaptados para monograf√≠a de tesis.

---

## 2. Visi√≥n general de la arquitectura

El sistema completo se puede entender en tres grandes capas funcionales:

### 2.1. Capa de Procesamiento de Datos y Modelos ML

- **Archivo principal**: `procesar_modelo.py` (866 l√≠neas, validado el 2025-12-13)
- **Entrada**: CSV originales con 23 columnas, 2.2M+ filas sin normalizar
- **Constantes de configuraci√≥n** (definidas en l√≠neas 20-24):
  - `Z_VALUE = 1.96`: nivel de confianza 95% para intervalos
  - `MAX_INTERVAL_RATIO = 1.35`: l√≠mite superior = 135% de la predicci√≥n
  - `MIN_INTERVAL_ABS = 500.0`: ancho m√≠nimo absoluto de intervalo
  - `MIN_CLASS_SAMPLES = 100`: soporte m√≠nimo para entrenar clasificadores
  - `DTYPE_OVERRIDES = {'tipo_carta': 'string'}`: fuerza tipo string para evitar DtypeWarning
- **Dataclasses de configuraci√≥n**:
  - `SamplingConfig`: `frac` (default 1.0), `n_per_month` (opcional), `random_state=42`
  - `ForecastConfig`: `horizon=12` (meses a proyectar)
- **Salida**:
  - `embargos_consolidado_mensual.csv`: dataset consolidado muestreado (7%)
  - `predicciones_oficios_validacion.csv` (277 bytes): validaci√≥n hist√≥rica (RMSE 80,515)
  - `predicciones_oficios_futuro.csv` (573 bytes): pron√≥stico 12 meses con intervalos
  - `predicciones_demandados_validacion.csv` (274 bytes): validaci√≥n (RMSE 41,706)
  - `predicciones_demandados_futuro.csv` (576 bytes): pron√≥stico 12 meses
  - `resultados_clasificaciones.csv` (2,188 bytes): m√©tricas + matrices de confusi√≥n JSON

### 2.2. Capa de Interfaces Interactivas (Dashboards)

- `dashboard_embargos.py`: dashboard exploratorio de embargos.
- `dashboard_predicciones.py`: dashboard de predicciones y m√©tricas de modelos.

Ambas son aplicaciones Streamlit que se ejecutan en el navegador y permiten:

- Filtrar, buscar y explorar embargos a nivel banco, ciudad, funcionario, tipo, estado, etc.
- Visualizar la evoluci√≥n temporal de oficios.
- Comparar valores reales vs. predichos (oficios y demandados).
- Analizar m√©tricas de precisi√≥n, *recall* y F1-score de los modelos de clasificaci√≥n.
- Exportar subconjuntos filtrados a CSV/Excel/JSON.

### 2.3. Capa de Orquestaci√≥n y Distribuci√≥n

- `launcher.py`: interfaz gr√°fica (Tkinter) que act√∫a como ‚Äúmen√∫ principal‚Äù para:
  - Seleccionar los CSV originales de la base de datos.
  - Ejecutar el procesamiento completo (limpieza + ML + generaci√≥n de archivos).
  - Iniciar los dashboards de embargos y de predicciones.
  - Ver el estado de los archivos generados y recalcularlos con nuevos datos.
- `utils_csv.py`: capa de abstracci√≥n para localizar archivos CSV en diferentes ubicaciones (AppData del usuario, carpeta del ejecutable, subcarpetas `datos`, etc.), indispensable para compatibilidad entre modo ‚Äúdesarrollo‚Äù y modo ‚Äúejecutable instalado‚Äù.
- `build_executable.py` e `installer_setup.iss`: scripts para empaquetar todo en un ejecutable √∫nico y generar un instalador de Windows.

Esta arquitectura cumple con el objetivo de la tesis de dos formas claras:

- Proporciona **interfaces de reporter√≠a avanzadas** (dashboards web interactivos) integradas a una l√≥gica de IA (modelos XGBoost y clasificadores).
- Automatiza **la generaci√≥n de reportes** (CSV de consolidado, predicciones y m√©tricas) y presenta los resultados en una **plataforma de gesti√≥n** (navegador, con Streamlit como framework).

---

## 3. Flujo de trabajo funcional del sistema

El flujo de uso t√≠pico del sistema, desde la perspectiva de un usuario final no t√©cnico, es el siguiente:

1. Ejecutar el programa `DashboardEmbargos.exe` (o instalarlo mediante el instalador y acceder desde el men√∫ de inicio).
2. Desde el `launcher.py` (interfaz gr√°fica):
   - Seleccionar uno o varios archivos CSV originales de la base de datos. Estos CSV siguen una convenci√≥n de nombres como `consulta detalle embargos-2023-01.csv`, `consulta detalle embargos-2023-02.csv`, etc.
   - Presionar **‚ÄúRecalcular archivos‚Äù** para procesar la informaci√≥n. El lanzador muestra una ventana de progreso donde se observa el avance del procesamiento, limpieza y entrenamiento de modelos.
3. El script `procesar_modelo.py` se ejecuta en segundo plano:
   - Concatena los CSV.
   - Normaliza, limpia y muestrea los datos.
   - Entrena modelos de regresi√≥n y clasificaci√≥n.
   - Genera los cuatro CSV de salida.
4. Desde el mismo `launcher.py`, el usuario puede:
   - Iniciar el **Dashboard de Embargos**.
   - Iniciar el **Dashboard de Predicciones**.
   - Detener dashboards activos.
   - Ver el estado de los archivos generados (checklist de archivos encontrados).
5. Los dashboards se abren en el navegador (`http://localhost:8501` y `http://localhost:8502`), donde el usuario puede explorar los datos, aplicar filtros, visualizar KPIs y descargar reportes.

De este modo, se logra un ciclo completo de ETL + ML + visualizaci√≥n, completamente orquestado desde una interfaz gr√°fica, sin necesidad de que el usuario final interact√∫e con la consola ni con el c√≥digo fuente.

---

## 4. Metodolog√≠a empleada (CRISP-DM y enfoque anal√≠tico)

Aunque no todo el detalle metodol√≥gico est√° expl√≠cito en comentarios, el proyecto se alinea con la metodolog√≠a **CRISP-DM (Cross-Industry Standard Process for Data Mining)**, con las siguientes fases reflejadas en el c√≥digo y en el flujo de trabajo:

### 4.1. Comprensi√≥n del negocio

- **Problema**: falta de visibilidad y capacidad predictiva sobre el volumen de embargos, los estados de los oficios y la distribuci√≥n de cargas entre bancos, ciudades y funcionarios.
- **Objetivo de negocio**:
  - Anticipar la carga operativa mensual.
  - Mejorar la planificaci√≥n de recursos humanos y tecnol√≥gicos.
  - Disponer de reportes autom√°ticos f√°cilmente consumibles por √°reas legales, riesgos y TI.

### 4.2. Comprensi√≥n de los datos

A partir del an√°lisis descrito en `ANALISIS_COLUMNAS.md` se identifica el rol de cada campo:

- **Columnas fundamentales** para el dashboard:
  - Filtros cr√≠ticos: `entidad_bancaria`, `ciudad`, `estado_embargo`, `tipo_embargo`, `mes`.
  - M√©tricas: `montoaembargar`, `es_cliente`.
  - Rankings/visualizaciones: `funcionario`, `entidad_remitente`, `tipo_documento`.
- **Columnas de b√∫squeda global**: `nombres`, `identificacion`.
- **Columnas poco usadas o no relevantes**: `correo`, `direccion`, `fecha_banco`, `fecha_oficio`, `referencia`, `cuenta`, `expediente`, `id`, `tipo_identificacion_tipo`.

Esta clasificaci√≥n permite centrar el procesamiento y las visualizaciones en los campos que realmente aportan valor al an√°lisis.

### 4.3. Preparaci√≥n de los datos

La preparaci√≥n de datos se realiza principalmente en `procesar_modelo.py`:

- **Lectura robusta de CSV**:
  - Soporte para m√∫ltiples codificaciones (`utf-8`, `latin-1`, `cp1252`, `iso-8859-1`).
  - Reparaci√≥n de filas con menos o m√°s columnas de las esperadas (23 columnas est√°ndar definidas en `expected_columns`).
- **Conversi√≥n y limpieza de variables num√©ricas y categ√≥ricas**:
  - `montoaembargar` se convierte a num√©rico, con manejo de errores y reemplazo de nulos por 0.
  - `es_cliente` se normaliza a una variable binaria (`0`/`1`) usando m√∫ltiples patrones (`SI`, `1`, `CLIENTE`, `TRUE`, etc.).
  - Campos categ√≥ricos (`ciudad`, `entidad_remitente`, `tipo_embargo`, `estado_embargo`, etc.) se convierten a texto en may√∫sculas, sin espacios sobrantes, y se reemplazan valores infrecuentes por la categor√≠a `OTRO`.
- **Tratamiento de fechas**:
  - Conversi√≥n de `fecha_banco` y `fecha_oficio` a `datetime`.
- **Derivaci√≥n de variables temporales**:
  - `a√±o`, `mes_num`: extra√≠dos de `fecha_banco` con `pd.to_datetime`
  - **Codificaci√≥n c√≠clica trigonom√©trica** (preserva continuidad diciembre‚Üíenero):
    ```python
    mes_sin = np.sin(2 * np.pi * mes_num / 12.0)
    mes_cos = np.cos(2 * np.pi * mes_num / 12.0)
    ```
  - `mes_index = a√±o * 12 + mes_num`: √≠ndice ordinal para tendencia lineal
  - `mes_label`: formato `"YYYY-MM"` para visualizaci√≥n
- **Features de rezago (lags) para series temporales**:
  - `oficios_lag1`, `oficios_lag2`, `oficios_lag3`: valores de 1, 2 y 3 meses anteriores
  - `oficios_ma3`: media m√≥vil 3 meses con `rolling(window=3, min_periods=1).mean().shift(1)`
  - An√°logos para demandados: `demandados_lag{1,2,3}`, `demandados_ma3`
- **Garant√≠a de continuidad temporal** (funci√≥n `_ensure_month_continuity`):
  - Rellena huecos en la serie mensual usando `pd.date_range(freq='MS')`
  - Imputa columnas num√©ricas con 0 para evitar NaN en lags
- **Muestreo estratificado por mes**:
  - Configurable via `--frac-muestra` (default 1.0) o `--n-muestra` (N filas/mes)
  - Implementado con `df.groupby('mes').apply(_sampler)` preservando distribuci√≥n temporal
  - Valor hist√≥rico: 7% para desarrollo (`frac=0.07`), 100% para producci√≥n

### 4.4. Modelado

#### Modelos de regresi√≥n (XGBRegressor con validaci√≥n hist√≥rica y pron√≥stico futuro)

**Arquitectura dual**: cada objetivo (oficios, demandados) entrena dos modelos XGBoost con objetivo Poisson:
1. **Modelo de validaci√≥n**: entrenado con a√±os < √∫ltimo, validado en √∫ltimo a√±o completo (split temporal)
2. **Modelo de pron√≥stico**: reentrenado con todo el hist√≥rico limpio, proyecci√≥n recursiva 12 meses

**Hiperpar√°metros XGBRegressor** (l√≠neas 327-331):
```python
XGBRegressor(
    n_estimators=200, learning_rate=0.1, max_depth=7,
    objective='count:poisson',  # Distribuci√≥n Poisson para conteos
    random_state=42,
    base_score=np.mean(y_train_clean)  # Predicci√≥n base = media hist√≥rica
)
```

**Pipeline de pron√≥stico extendido** (`entrenar_modelos_y_generar_predicciones`):
1. **Preprocesamiento temporal**: agregaci√≥n mensual con `groupby(['a√±o', 'mes_num'])`, continuidad garantizada por `_ensure_month_continuity`
2. **Validaci√≥n hist√≥rica**: split `train[a√±o < ultimo_a√±o]` vs `test[a√±o == ultimo_a√±o]`, c√°lculo RMSE/MAE, escala residual para intervalos
3. **Algoritmo de intervalos acotados** (funci√≥n `_compute_interval`, l√≠neas 48-52):
   ```python
   def _compute_interval(residual_scale, horizonte, pred_value):
       base = residual_scale if residual_scale > 0 else 1.0
       raw_interval = Z_VALUE * base * np.sqrt(max(1, horizonte))  # Crece con ra√≠z del horizonte
       cap = max(pred_value * MAX_INTERVAL_RATIO, MIN_INTERVAL_ABS)  # L√≠mite superior
       return float(np.clip(raw_interval, 0.0, cap))  # Truncamiento
   ```
   - **L√≥gica**: intervalo crece proporcional a $\sqrt{h}$ donde $h$ es horizonte en meses
   - **Truncamiento**: evita explosiones num√©ricas limitando a 135% predicci√≥n o 500 m√≠nimo
   - **Resultado**: horizontes >3 frecuentemente tienen `limite_inferior=0` por truncamiento
4. **Etiquetado cualitativo** (funci√≥n `_confidence_label`):
   - Alta: horizonte ‚â§ 3 meses
   - Media: horizonte ‚â§ 6 meses
   - Baja: horizonte > 6 meses
5. **Pron√≥stico recursivo** (l√≠neas 398-447): actualiza lags con predicci√≥n anterior, itera 12 meses

**Salidas**:
- `predicciones_{stub}_validacion.csv`: mes, real, pred (RMSE oficios=80,515; demandados=41,706)
- `predicciones_{stub}_futuro.csv`: mes, pred, l√≠mite_inferior, l√≠mite_superior, nivel_confianza, horizonte_meses

#### Modelos de clasificaci√≥n (XGBClassifier con filtrado autom√°tico por soporte)

**Mejora cr√≠tica**: funci√≥n `prepare_multiclass_dataset` (l√≠neas 675-693) filtra clases con soporte < `MIN_CLASS_SAMPLES=100` antes del entrenamiento:

```python
def prepare_multiclass_dataset(feature_cols, target_col, encoder, min_samples=MIN_CLASS_SAMPLES):
    target_series = df[target_col].copy()
    counts = target_series.value_counts()
    valid_codes = counts[counts >= min_samples].index.tolist()
    if len(valid_codes) < 2:
        return None  # No hay suficientes clases v√°lidas
    discarded = counts[counts < min_samples]
    if not discarded.empty:
        print(f"[INFO] {target_col}: se descartan {len(discarded)} clases con soporte < {min_samples}")
    # Re-encoding con LabelEncoder local para clases filtradas
    mask = target_series.isin(valid_codes)
    subset_encoder = LabelEncoder()
    y_encoded = subset_encoder.fit_transform(labels_text)
    return X_local, y_encoded, label_names
```

**Hiperpar√°metros XGBClassifier** (l√≠neas 703-709):
```python
XGBClassifier(
    n_estimators=100, max_depth=7, learning_rate=0.1,
    subsample=0.9, colsample_bytree=0.8,  # Regularizaci√≥n
    eval_metric='mlogloss',  # Log-loss multiclase
    tree_method="hist"  # Algoritmo r√°pido basado en histogramas
)
```

**Tres clasificadores principales**:

1. **Tipo Embargo** (COACTIVO/JUDICIAL):
   - Features: `['entidad_remitente_enc', 'mes_num', 'montoaembargar', 'estado_embargo_enc', 'es_cliente_bin']`
   - Split: 80% train / 20% test con `stratify=y_tipo`
   - Resultados validados: COACTIVO F1=0.991, JUDICIAL F1=0.976
   - Clases descartadas: `PROCESADO` (22 casos), `SIN_PROCESAR` (55 casos)

2. **Estado Embargo**:
   - Features adicional: `tipo_embargo_enc` (5 features total)
   - CONFIRMADO F1=0.780, PROCESADO F1=0.770
   - Descartados: `PROCESADO_CON_ERRORES` (48), `DESEMBARGO` (13)

3. **Cliente / No Cliente** (clasificaci√≥n binaria):
   - **Manejo de desbalance**: `scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()`
   - `eval_metric='auc'` (√Årea bajo curva ROC, apropiado para binario desbalanceado)
   - NO_CLIENTE F1=0.923, CLIENTE F1=0.508 (desbalance ~12:1 en datos)

**Serializaci√≥n de matrices de confusi√≥n** (funci√≥n `report_to_df`, l√≠neas 653-672):
- Columna `matriz_confusion`: JSON de lista 2D (`[[TP, FP], [FN, TN]]`)
- Columna `clases_matriz`: JSON de etiquetas ordenadas (`["COACTIVO", "JUDICIAL"]`)
- Validadas por `test_matrices_load.py`: deserializaci√≥n exitosa, suma 442,066 obs/modelo, sin NaN

**Formato `resultados_clasificaciones.csv`**:
```csv
modelo,clase,precision,recall,f1,soporte,matriz_confusion,clases_matriz
Tipo Embargo,COACTIVO,0.990,0.991,0.991,323407,"[[320113, 3294], [1858, 118101]]","[\"COACTIVO\", \"JUDICIAL\"]"
```

### 4.5. Evaluaci√≥n

#### 4.5.1. M√©tricas de regresi√≥n (consola)

Para modelos de regresi√≥n se calculan y reportan en consola durante el entrenamiento:
- **RMSE (Root Mean Squared Error)**: penaliza errores grandes, sensible a outliers
- **MAE (Mean Absolute Error)**: error promedio en unidades originales, m√°s robusto

Valores actuales validados:
| Modelo | RMSE | MAE | Promedio real |
|--------|------|-----|---------------|
| Oficios | 80,515 | 70,225 | 103,458 |
| Demandados | 41,706 | 38,425 | 53,529 |

#### 4.5.2. M√©tricas de clasificaci√≥n (CSV persistido)

Para clasificadores se genera `resultados_clasificaciones.csv` con:
- **Precisi√≥n**: $\frac{TP}{TP + FP}$ ‚Äî de los predichos positivos, ¬øcu√°ntos acert√≥?
- **Recall**: $\frac{TP}{TP + FN}$ ‚Äî de los reales positivos, ¬øcu√°ntos detect√≥?
- **F1-score**: $2 \times \frac{precision \times recall}{precision + recall}$ ‚Äî media arm√≥nica
- **Soporte**: n√∫mero de muestras por clase en el test set

#### 4.5.3. Tests automatizados de integraci√≥n

El proyecto incluye tres scripts de smoke testing para validar la integridad del pipeline:

**1. `test_dashboard_load.py`** (66 l√≠neas):
```python
# Simula la l√≥gica de carga del dashboard
dtype_dict = {'modelo': 'category', 'clase': 'category'}
df = pd.read_csv(csv_path, dtype=dtype_dict, engine='c')
# Verifica: columnas esperadas, encoding multi-fallback, NaN en campos cr√≠ticos
```
- Valida columnas: `modelo`, `clase`, `precision`, `recall`, `f1`, `soporte`
- Multi-encoding fallback: utf-8 ‚Üí latin-1 ‚Üí cp1252 ‚Üí iso-8859-1

**2. `test_matrices_load.py`** (73 l√≠neas):
```python
# Deserializa matrices JSON y verifica integridad
cm = np.array(json.loads(primera_fila['matriz_confusion']))
clases = json.loads(primera_fila['clases_matriz'])
# Valida: suma observaciones = 442,066, sin NaN, dimensiones correctas
```
- Verifica `matriz_confusion` y `clases_matriz` para cada modelo
- Confirma suma de observaciones consistente por modelo

**3. `test_predicciones_futuras.py`** (63 l√≠neas):
```python
# Ejecuta pipeline completo y verifica archivos generados
entrenar_modelos_y_generar_predicciones(consolidado_path, output_dir)
# Valida: 5 archivos esperados, tama√±o > 0, columnas correctas
```
- Verifica generaci√≥n de archivos: `predicciones_oficios_validacion.csv`, `predicciones_oficios_futuro.csv`, `predicciones_demandados_validacion.csv`, `predicciones_demandados_futuro.csv`, `resultados_clasificaciones.csv`

**Ejecuci√≥n de tests**:
```bash
python test_dashboard_load.py       # ~2 segundos
python test_matrices_load.py        # ~1 segundo
python test_predicciones_futuras.py # ~45 segundos (entrena modelos)
```

### 4.6. Despliegue

#### 4.6.1. Interfaz de l√≠nea de comandos (CLI)

El script `procesar_modelo.py` expone una interfaz CLI completa (funci√≥n `parse_arguments`, l√≠neas 796-810):

```bash
python procesar_modelo.py <csv_files...> [opciones]

Argumentos posicionales:
  csv_files           Rutas a los archivos CSV originales (acepta m√∫ltiples)

Opciones:
  --output-dir DIR    Directorio de salida (default: AppData/DashboardEmbargos/datos)
  --frac-muestra F    Fracci√≥n mensual a muestrear, 0.0-1.0 (default: 1.0)
  --n-muestra N       N√∫mero m√°ximo de filas por mes (prioridad sobre frac)
  --horizonte H       Meses futuros a pronosticar (default: 12)
  --random-state S    Semilla para reproducibilidad (default: 42)
```

**Ejemplos de uso**:
```bash
# Procesar todos los CSV del 2024 con muestreo 10%
python procesar_modelo.py "datos/embargos-2024-*.csv" --frac-muestra 0.10

# Pron√≥stico extendido de 24 meses
python procesar_modelo.py datos/*.csv --horizonte 24 --output-dir ./resultados
```

#### 4.6.2. Empaquetado y distribuci√≥n

- El proceso de despliegue incluye:
  - Empaquetado del sistema con PyInstaller (`build_executable.py`), generando un √∫nico ejecutable `DashboardEmbargos.exe`.
  - Creaci√≥n de un instalador Windows con Inno Setup (`installer_setup.iss`), produciendo `DashboardEmbargos_Installer.exe`.
  - Uso de scripts auxiliares (`crear_instalador.ps1`, `crear_instalador.bat`) para automatizar la construcci√≥n.
- El ejecutable incluye todas las dependencias (Python embebido, Streamlit, pandas, scikit-learn, xgboost, etc.), de manera que el usuario final solo necesita ejecutar el instalador.

---

## 5. Descripci√≥n detallada de los componentes de reporter√≠a

### 5.1. Dashboard de Embargos (`dashboard_embargos.py`)

Es la **interface principal de reporter√≠a exploratoria** sobre embargos.

#### 5.1.1. Carga de datos optimizada

La funci√≥n `load_data()` realiza:

- Localizaci√≥n de `embargos_consolidado_mensual.csv` usando `utils_csv`.
- Detecci√≥n de codificaci√≥n con `chardet`.
- Lectura con `pandas.read_csv` utilizando tipos optimizados:
  - Campos categ√≥ricos (`category`) para disminuir memoria.
  - `montoaembargar` como `float32`.
- Normalizaci√≥n de `es_cliente` a valores binarios.
- Eliminaci√≥n de filas solo si tienen NaN en columnas **fundamentales**, siguiendo el an√°lisis de `ANALISIS_COLUMNAS.md`.

#### 5.1.2. Sistema de filtros avanzado

Se implementa un sistema de filtros muy completo:

- Filtros por entidad bancaria, ciudad, estado del embargo, tipo de embargo y mes.
- B√∫squeda global por banco, ciudad, entidad remitente, nombres e identificaci√≥n.
- Normalizaci√≥n de valores de `estado_embargo` y `tipo_embargo`:
  - Estados normalizados: `CONFIRMADO`, `PROCESADO`, `SIN_CONFIRMAR`, `PROCESADO_CON_ERRORES`, agrupando m√∫ltiples variantes de texto.
  - Tipos normalizados: `JUDICIAL`, `COACTIVO`, tambi√©n con mapeo de variaciones.

La funci√≥n `apply_filters_fast` es cacheada y est√° dise√±ada para **no bloquear** la interfaz, incluso cuando hay muchos filtros activos o conjuntos de datos grandes.

#### 5.1.3. M√©tricas ejecutivas en tiempo real

Las m√©tricas se calculan en `calculate_metrics` y se muestran como tarjetas visuales:

- Total de oficios.
- Monto total embargado.
- Promedio de oficios por mes.
- N√∫mero de registros visualizados (hasta 100 en la tabla, pero mostrando el total real encontrado).
- Porcentaje de clientes.
- Monto promedio por oficio.
- Oficios activos.
- N√∫mero de embargos judiciales.

Estas m√©tricas proporcionan un **resumen ejecutivo inmediato** de la situaci√≥n para los filtros seleccionados.

#### 5.1.4. Visualizaciones principales

En la pesta√±a **‚ÄúDashboard Principal‚Äù** se incluyen:

- **Distribuci√≥n por tipo de embargo** (gr√°fico de pastel):
  - Solo se muestran los tipos v√°lidos `JUDICIAL` y `COACTIVO`.
  - Los valores inconsistentes se normalizan y filtran.

- **Distribuci√≥n por estado del embargo** (gr√°fico de barras):
  - Se consideran √∫nicamente los estados normalizados v√°lidos.

- **Rankings Top 10**:
  - Entidades bancarias (solo bancos reales, excluyendo textos que son estados mal ubicados).
  - Top 10 ciudades.
  - Top 10 funcionarios.
  - Top 10 entidades remitentes.

- **Evoluci√≥n mensual de oficios**:
  - Gr√°fico de l√≠nea con el conteo de oficios por mes.
  - Eje temporal ordenado correctamente por `mes` (`YYYY-MM`).

- **Proporci√≥n Judicial vs Coactivo (mensual)**:
  - Gr√°fico de √°rea apilada con proporciones por mes.
  - Permite observar estacionalidad y cambios en la composici√≥n de tipos de embargo.

#### 5.1.5. Otras pesta√±as anal√≠ticas

- **Tendencias y Rankings**:
  - Enfocado en la serie temporal de oficios mensuales.

- **An√°lisis Geogr√°fico**:
  - Distribuci√≥n por ciudad (barras horizontales de montos).
  - Matriz Ciudad vs Banco (mapa de calor) para analizar concentraci√≥n y cobertura.

- **An√°lisis Detallado**:
  - Distribuci√≥n de montos: histograma con exclusi√≥n de ceros y outliers.
  - Estad√≠sticas detalladas (m√≠nimo, m√°ximo, mediana, cuartiles, desviaci√≥n est√°ndar).
  - An√°lisis de clientes vs no clientes (pastel).
  - Distribuci√≥n de tipos de documento (`tipo_documento`).

- **Exportaci√≥n**:
  - Descarga del subconjunto filtrado en CSV, Excel (si `openpyxl` est√° disponible) y JSON.
  - Resumen de cu√°ntos registros y columnas se exportan.

En conjunto, este dashboard materializa la parte de **visualizaci√≥n de datos en plataformas de gesti√≥n**, proporcionando una interface rica, navegable y con filtros de negocio que permiten generar reportes ad hoc sin escribir c√≥digo ni consultas SQL.

### 5.2. Dashboard de Predicciones y M√©tricas (`dashboard_predicciones.py`)

Centra la **reporter√≠a anal√≠tica basada en IA** (1,451 l√≠neas), exponiendo resultados de modelos de regresi√≥n/clasificaci√≥n con capacidades avanzadas de validaci√≥n y proyecci√≥n.

#### 5.2.1. Arquitectura de carga validada

**Funci√≥n `load_csv(name)`** con cache invalidado por `mtime` del archivo:
```python
@st.cache_data(ttl=3600)  # Cache de 1 hora
def load_csv(name):
    # Detecci√≥n autom√°tica de encoding con fallback
    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc, dtype=dtype_dict)
            break
        except UnicodeDecodeError:
            continue
```

- **dtype condicional**: float para predicciones, category para modelo/clase
- **Validaci√≥n de columnas** esperadas con mensajes descriptivos
- **Tests automatizados**: `test_dashboard_load.py`, `test_matrices_load.py`
- **Archivos consumidos** (4 CSV + 1 m√©tricas):
  - `predicciones_oficios_validacion.csv`: mes, real_oficios, pred_oficios
  - `predicciones_oficios_futuro.csv`: mes, pred, limite_inferior/superior, nivel_confianza, horizonte
  - `predicciones_demandados_validacion.csv`: mes, real_demandados, pred_demandados
  - `predicciones_demandados_futuro.csv`: an√°logo a oficios
  - `resultados_clasificaciones.csv`: m√©tricas + matrices JSON

#### 5.2.2. Pesta√±a: Oficios (Validaci√≥n + Futuro)

**Validaci√≥n hist√≥rica** (per√≠odo 2024-01 a 2024-09):
- **Gr√°fico de l√≠nea dual**: real vs predicho con Plotly, leyenda interactiva
- **KPIs destacados**: RMSE 80,515 | MAE 70,225 | Promedio real 103,458
- **Tabla paginada**: mes, real, predicho, residual (real - pred), error % 
- **Descarga CSV**: validaci√≥n completa con residuales calculados

**Pron√≥stico futuro** (12 meses con intervalos):
- **Gr√°fico con banda de confianza**: √°rea sombreada limite_inferior ‚Üî limite_superior
- **Niveles cualitativos**: coloreado por Alta (verde) / Media (amarillo) / Baja (rojo)
- **Tarjetas m√©tricas**:
  - Pr√≥ximo mes: 112,725 oficios
  - Acumulado anual: 1.64M oficios
  - Nivel confianza pr√≥ximo: Alta
- **Advertencia visual**: icono ‚ö†Ô∏è cuando `limite_inferior=0` (horizontes >3 por truncamiento)

#### 5.2.3. Pesta√±a: Demandados (estructura id√©ntica)

- RMSE 41,706 | MAE 38,425 | Promedio real 53,529
- Pr√≥ximo mes: 103,112 demandados | Proyecci√≥n anual: 918K
- Intervalos truncados en horizontes lejanos (misma l√≥gica que oficios)

#### 5.2.4. Pesta√±a: M√©tricas de Clasificaci√≥n

**Tabla consolidada interactiva**:
- Columnas visibles: modelo, clase, precision, recall, f1, soporte
- Columnas ocultas: matriz_confusion (JSON), clases_matriz (JSON)
- Filtros din√°micos: selector de modelo, selector de clase
- Paginaci√≥n: 10 filas por p√°gina con navegaci√≥n
- Descarga: CSV completo con todas las columnas

**Visualizaci√≥n de matrices de confusi√≥n**:
- Selector de modelo ‚Üí renderiza heatmap Plotly
- Diagonal resaltada (aciertos) vs celdas claras (errores)
- Anotaci√≥n de valores absolutos en cada celda
- Ejemplo Tipo Embargo: `[[320113, 3294], [1858, 118101]]` = 99.0% precisi√≥n diagonal

**Sistema de tooltips educativos** (diccionario `HELPS`, l√≠neas 78-87):
```python
HELPS = {
    "mae": "Error Absoluto Medio: promedio de la magnitud de errores...",
    "rmse": "Ra√≠z del Error Cuadr√°tico Medio: penaliza errores grandes...",
    "f1_score": "F1-Score: m√©trica balanceada entre precisi√≥n y recall...",
    "precision": "Precisi√≥n: de los predichos positivos, ¬øcu√°ntos acert√≥?",
    "recall": "Recall: de los reales positivos, ¬øcu√°ntos detect√≥?",
    "matriz_confusion": "Tabla que muestra aciertos (diagonal) y confusiones..."
}
```
- Iconos `‚ÑπÔ∏è` con hover que despliegan explicaci√≥n completa
- Dirigido a usuarios no t√©cnicos (√°reas legales, riesgos)

Este dashboard **transparenta la caja negra de IA**, esencial para tesis y contextos regulados (auditor√≠a, cumplimiento).

---

## 6. Orquestaci√≥n y automatizaci√≥n: `launcher.py` y `utils_csv.py`

### 6.1. `launcher.py`

El archivo `launcher.py` funciona como un **hub de orquestaci√≥n** que conecta datos, modelos, dashboards y empaquetado. Sus responsabilidades principales son:

- **Gesti√≥n de CSV de origen de BD**:
  - Permite seleccionar uno o varios archivos CSV originales.
  - Muestra de forma resumida cu√°ntos archivos se han seleccionado.

- **Estado de archivos generados**:
  - Verifica la existencia de 6 archivos:
    - `embargos_consolidado_mensual.csv`
    - `predicciones_oficios_validacion.csv` + `predicciones_oficios_futuro.csv`
    - `predicciones_demandados_validacion.csv` + `predicciones_demandados_futuro.csv`
    - `resultados_clasificaciones.csv`
  - Presenta este estado mediante checkboxes deshabilitados pero coloreados (verde si existe, rojo si falta).

- **Recalcular archivos (pipeline completo)**:
  - Llama a `ejecutar_procesamiento`, que:
    - Invoca `procesar_csv_original` y `entrenar_modelos_y_generar_predicciones`.
    - Redirige la salida a una ventana de progreso con texto detallado.
    - Permite que el usuario lea errores y mensajes intermedios antes de cerrar.

- **Inicio de dashboards**:
  - `start_embargos_dashboard` y `start_predicciones_dashboard`:
    - Verifican que los CSV requeridos existan (si no, solicitan o ejecutan el procesamiento).
    - Localizan los scripts `dashboard_embargos.py` y `dashboard_predicciones.py` en distintas rutas posibles (ejecutable, `_MEIPASS`, carpeta del proyecto).
    - Llaman a `run_streamlit`, que:
      - Copia los scripts (y `utils_csv.py`) a una carpeta de datos del usuario si es necesario (para evitar problemas de permisos en `Program Files`).
      - Lanza un proceso Streamlit en un puerto disponible.
      - Redirige logs a archivos `streamlit_embargos.log` y `streamlit_predicciones.log`.

- **Control de procesos**:
  - Permite detener todos los dashboards activos.
  - Maneja el cierre de la aplicaci√≥n preguntando al usuario si desea detener procesos que est√°n corriendo.

### 6.2. `utils_csv.py`

`utils_csv.py` proporciona una capa de abstracci√≥n para encontrar y escribir archivos en distintos contextos (desarrollo vs ejecutable instalado):

- **`get_base_path()`**: devuelve la ruta base donde est√° el ejecutable o, en modo desarrollo, el proyecto.
- **`get_data_path()`**: determina una carpeta segura para escribir archivos CSV:
  - En Windows ejecutable: `AppData\Roaming\DashboardEmbargos\datos`.
  - En desarrollo: carpeta del proyecto (y opcionalmente subcarpeta `datos`).
- **`find_csv_file(filename)`**: busca un archivo en m√∫ltiples ubicaciones, en orden de prioridad:
  1. Carpeta de datos del usuario (AppData).
  2. Carpeta base.
  3. Subcarpetas `datos` o `data`.
  4. Carpeta actual.
- **`get_csv_path(filename, required=True)`**: usa `find_csv_file` y, si no encuentra el archivo y `required=True`, lanza un `FileNotFoundError` con un mensaje detallado explicando d√≥nde se busc√≥ y qu√© hacer.

Sin estas utilidades, la aplicaci√≥n tendr√≠a problemas de permisos y rutas, especialmente cuando se ejecuta instalada en `Program Files` en Windows.

---

## 7. Resultados validados experimentalmente

### 7.1. Dataset consolidado y normalizado (parcialmente)

**Archivo**: `embargos_consolidado_mensual.csv`
- **Dimensiones**: 2,227,458 filas √ó 23 columnas (muestreo 7% mensual)
- **Tama√±o en disco**: ~180 MB (comprimido ~45 MB)
- **Cobertura temporal**: 2020-01 a 2024-12 (60 meses)

**Normalizaciones aplicadas en `procesar_csv_original`**:
1. `DTYPE_OVERRIDES={'tipo_carta': 'string'}`: fuerza tipo para evitar DtypeWarning
2. `es_cliente` binarizado: m√∫ltiples patrones (`SI`, `1`, `CLIENTE`, `TRUE`, `YES`, `S√ç`) ‚Üí `1`
3. Categor√≠as raras ‚Üí `OTRO` para reducir cardinalidad
4. Fechas parseadas con `pd.to_datetime(..., errors='coerce')`
5. Filas corregidas: columnas < 23 rellenadas con vac√≠o, > 23 truncadas

**Limitaciones documentadas** (heredadas de datos fuente):
- Montos sin estandarizaci√≥n (mezcla de escalas)
- Valores categ√≥ricos con variantes ortogr√°ficas no normalizadas
- Reflejado en RMSE elevados e intervalos truncados

### 7.2. Pron√≥sticos validados con horizonte extendido

**Archivos de validaci√≥n hist√≥rica** (per√≠odo test: √∫ltimo a√±o disponible):

| Archivo | Tama√±o | Columnas | Per√≠odo validaci√≥n |
|---------|--------|----------|-------------------|
| `predicciones_oficios_validacion.csv` | 277 bytes | mes, real_oficios, pred_oficios | 2024-01 a 2024-09 |
| `predicciones_demandados_validacion.csv` | 274 bytes | mes, real_demandados, pred_demandados | 2024-01 a 2024-09 |

**M√©tricas de validaci√≥n** (calculadas en `entrenar_modelos_y_generar_predicciones`):

| Modelo | RMSE | MAE | Promedio real | MAPE estimado |
|--------|------|-----|---------------|---------------|
| Oficios | 80,515 | 70,225 | 103,458 | ~68% |
| Demandados | 41,706 | 38,425 | 53,529 | ~72% |

> **Nota**: MAPE elevado debido a predicciones saturadas en meses iniciales (oficios ‚âà1,857 vs real 99k‚Äì113k) por lags con NaN imputados como 0.

**Archivos de pron√≥stico futuro** (horizonte 12 meses):

| Archivo | Tama√±o | Columnas |
|---------|--------|----------|
| `predicciones_oficios_futuro.csv` | 573 bytes | mes, pred_oficios, limite_inferior, limite_superior, nivel_confianza, horizonte_meses |
| `predicciones_demandados_futuro.csv` | 576 bytes | mes, pred_demandados, limite_inferior, limite_superior, nivel_confianza, horizonte_meses |

**Proyecciones principales**:
- **Oficios**: pr√≥ximo mes 112,725 | acumulado 12 meses 1.64M
- **Demandados**: pr√≥ximo mes 103,112 | acumulado 12 meses 918K
- Niveles de confianza: Alta (h‚â§3), Media (h‚â§6), Baja (h>6)
- Intervalos [0, N] para h>3 (l√≠mite inferior negativo ‚Üí `max(0, *)` por truncamiento)

### 7.3. M√©tricas de clasificaci√≥n con filtrado por soporte

**Archivo**: `resultados_clasificaciones.csv` (2,188 bytes)
- **Observaciones totales por modelo**: 442,066 (validado por `test_matrices_load.py`)
- **Formato**: modelo, clase, precision, recall, f1, soporte, matriz_confusion (JSON), clases_matriz (JSON)

**Resumen de rendimiento por modelo**:

| Modelo | Clases v√°lidas | Mejores F1 | Clases descartadas (<100 muestras) |
|--------|----------------|------------|-----------------------------------|
| Tipo Embargo | COACTIVO, JUDICIAL | 0.991, 0.976 | PROCESADO (22), SIN_PROCESAR (55) |
| Estado Embargo | CONFIRMADO, PROCESADO, SIN_CONFIRMAR | 0.780, 0.770, 0.650 | PROCESADO_CON_ERRORES (48), DESEMBARGO (13) |
| Cliente | NO_CLIENTE, CLIENTE | 0.923, 0.508 | N/A (binario con scale_pos_weight) |

**Matrices de confusi√≥n ejemplo** (Tipo Embargo):
```
                 Pred: COACTIVO  Pred: JUDICIAL
Real: COACTIVO       320,113         3,294      (97.0% recall)
Real: JUDICIAL         1,858       118,101      (98.5% recall)
```

### 7.4. Interfaces de reporter√≠a validadas por smoke tests

**Dashboard embargos** (`dashboard_embargos.py`, 1,644 l√≠neas):
- Procesamiento de 2,227,458 registros sin bloqueo de UI
- Filtros vectorizados con `@st.cache_data` (respuesta <100ms tras cache)
- 8 KPIs ejecutivos calculados en tiempo real
- 6 tipos de gr√°ficos Plotly (pastel, barras, l√≠nea, √°rea, heatmap, histograma)
- Exportaci√≥n validada: CSV, Excel (openpyxl), JSON

**Dashboard predicciones** (`dashboard_predicciones.py`, 1,451 l√≠neas):
- Carga de 4 CSV + 1 m√©tricas con fallback multi-encoding
- 3 pesta√±as especializadas (Oficios, Demandados, Clasificaci√≥n)
- Deserializaci√≥n JSON de matrices sin errores
- Tooltips contextuales para 6 m√©tricas diferentes

**Suite de tests automatizados** (ejecutados 2025-12-13):
```bash
$ python test_dashboard_load.py      # ‚úì Columnas cr√≠ticas validadas
$ python test_matrices_load.py       # ‚úì JSON deserializado, 442,066 obs/modelo
$ python test_predicciones_futuras.py # ‚úì 5 archivos generados correctamente
```

---

## 8. Alineaci√≥n con el objetivo de tesis

El objetivo planteado es:

> *‚ÄúDesarrollar interfaces de reporter√≠a con inteligencia artificial, permitiendo la generaci√≥n de reportes automatizados y la visualizaci√≥n de datos en plataformas de gesti√≥n.‚Äù*

C√≥mo lo cumple el proyecto:

### 8.1. An√°lisis de cumplimiento por componente

#### Interfaces de reporter√≠a

| Componente | Implementaci√≥n | L√≠neas c√≥digo | Tecnolog√≠a |
|------------|----------------|---------------|------------|
| Dashboard Embargos | Exploraci√≥n hist√≥rica, filtros, KPIs | 1,644 | Streamlit + Plotly |
| Dashboard Predicciones | Pron√≥sticos, validaci√≥n, m√©tricas ML | 1,451 | Streamlit + Plotly |
| Launcher GUI | Orquestaci√≥n visual para usuarios no t√©cnicos | ~400 | Tkinter |

**Caracter√≠sticas de reporter√≠a implementadas**:
- Dise√±o responsivo con paleta corporativa (`#bfe084`, `#3c8198`, `#424e71`, `#252559`)
- Filtros multinivel (7 dimensiones: banco, ciudad, estado, tipo, mes, tipo_documento, b√∫squeda global)
- Exportaci√≥n multiformat (CSV, Excel via openpyxl, JSON)
- Paginaci√≥n de tablas con conteo de resultados
- Cache inteligente (`@st.cache_data`) para respuesta sub-segundo

#### Inteligencia artificial integrada

| Modelo | Objetivo | Algoritmo | M√©tricas validadas |
|--------|----------|-----------|-------------------|
| Regresi√≥n Oficios | Pron√≥stico mensual | XGBRegressor (Poisson) | RMSE 80,515 |
| Regresi√≥n Demandados | Pron√≥stico mensual | XGBRegressor (Poisson) | RMSE 41,706 |
| Clasificador Tipo Embargo | COACTIVO/JUDICIAL | XGBClassifier | F1 0.99/0.98 |
| Clasificador Estado | CONFIRMADO/PROCESADO/... | XGBClassifier | F1 0.78/0.77 |
| Clasificador Cliente | Binario (desbalanceado) | XGBClassifier | F1 0.92/0.51 |

**Innovaciones de IA implementadas**:
- Pron√≥stico recursivo 12 meses con actualizaci√≥n de lags
- Intervalos de confianza adaptativos con truncamiento inteligente
- Filtrado autom√°tico por soporte m√≠nimo (`MIN_CLASS_SAMPLES=100`)
- Manejo de desbalance con `scale_pos_weight` autom√°tico
- Serializaci√≥n de matrices de confusi√≥n para auditor√≠a

#### Generaci√≥n automatizada de reportes

**Pipeline ETL + ML completamente autom√°tico** (`procesar_modelo.py`):
```
CSV crudos BD ‚Üí Consolidaci√≥n ‚Üí Limpieza ‚Üí Features ‚Üí Entrenamiento ‚Üí Predicci√≥n ‚Üí 6 CSV salida
    (input)        (concat)    (normalize)  (lags)     (XGBoost)    (recursivo)    (output)
```

**Archivos generados autom√°ticamente** (sin intervenci√≥n post-selecci√≥n de CSV):
1. `embargos_consolidado_mensual.csv` ‚Äî dataset unificado
2. `predicciones_oficios_validacion.csv` ‚Äî m√©tricas validaci√≥n
3. `predicciones_oficios_futuro.csv` ‚Äî pron√≥stico 12 meses
4. `predicciones_demandados_validacion.csv` ‚Äî m√©tricas validaci√≥n
5. `predicciones_demandados_futuro.csv` ‚Äî pron√≥stico 12 meses
6. `resultados_clasificaciones.csv` ‚Äî m√©tricas + matrices confusi√≥n

#### Visualizaci√≥n en plataformas de gesti√≥n

**Caracter√≠sticas de plataforma**:
- Servidor local Streamlit (puertos 8501, 8502)
- Consumo via navegador web est√°ndar (Chrome, Edge, Firefox)
- Sin instalaci√≥n adicional para usuarios finales (ejecutable autocontenido)
- Compatible con estaciones de trabajo corporativas Windows

**Distribuci√≥n profesional**:
- PyInstaller ‚Üí ejecutable √∫nico `DashboardEmbargos.exe`
- Inno Setup ‚Üí instalador `DashboardEmbargos_Installer.exe`
- AppData para persistencia de datos (evita permisos de administrador)

### 8.2. Conclusi√≥n de alineaci√≥n

El proyecto constituye un **caso pr√°ctico completo y funcional** que demuestra la viabilidad de integrar ML en reporter√≠a empresarial, automatizar el ciclo end-to-end desde datos crudos hasta visualizaci√≥n, y desplegar profesionalmente sin dependencias t√©cnicas.

Cumple √≠ntegramente el objetivo de tesis al implementar los cuatro pilares: **interfaces de reporter√≠a**, **inteligencia artificial**, **generaci√≥n automatizada**, y **visualizaci√≥n en plataformas de gesti√≥n**.

---

## 9. Conclusiones y l√≠neas investigativas futuras

El sistema constituye una **soluci√≥n integral de anal√≠tica predictiva end-to-end** con las siguientes caracter√≠sticas validadas:

### 9.1. Logros demostrados experimentalmente

#### Procesamiento robusto de datos heterog√©neos
- **Escala**: 2.2M+ registros procesados en pipeline automatizado
- **Resiliencia**: reparaci√≥n de filas malformadas (< o > 23 columnas)
- **Flexibilidad**: soporte multi-encoding (utf-8, latin-1, cp1252, iso-8859-1)
- **Reproducibilidad**: semilla configurable `random_state=42` para muestreo

#### Capacidad predictiva con intervalos de confianza
- **Pron√≥stico extendido**: 12 meses con actualizaci√≥n recursiva de lags
- **Cuantificaci√≥n de incertidumbre**: intervalos adaptativos $Z \times \sigma \times \sqrt{h}$
- **Etiquetado cualitativo**: niveles Alta/Media/Baja por horizonte
- **M√©tricas de validaci√≥n**: RMSE oficios 80,515 | demandados 41,706

#### Transparencia y auditabilidad de IA
- **Matrices de confusi√≥n** serializadas en JSON y visualizadas como heatmaps
- **Filtrado por soporte** (`MIN_CLASS_SAMPLES=100`) documentado en logs
- **Tooltips educativos** explicando MAE/RMSE/F1/Precisi√≥n/Recall
- **Limitaciones** documentadas honestamente en informes t√©cnicos

#### Despliegue profesional y accesible
- **Ejecutable √∫nico**: PyInstaller con todas las dependencias embebidas
- **Instalador Windows**: Inno Setup con acceso directo en men√∫ inicio
- **Persistencia en AppData**: evita problemas de permisos en Program Files
- **Smoke tests**: 3 scripts de validaci√≥n automatizada

### 9.2. Limitaciones documentadas (base para investigaci√≥n futura)

Estas limitaciones est√°n detalladas en los informes t√©cnicos especializados y representan oportunidades de mejora:

| Limitaci√≥n | Causa ra√≠z | Impacto | Informe de referencia |
|------------|-----------|---------|----------------------|
| Intervalos truncados (h>3) | Residuos elevados sin log-transform | limite_inferior=0 | INFORME_VALIDACION_MODELO_ML.md |
| Predicciones saturadas iniciales | Lags con NaN imputados como 0 | MAPE ~68-72% | INFORME_VALIDACION_MODELO_ML.md |
| DtypeWarning persistente | tipo_carta con valores mixtos | Advertencia en carga | INFORME_VALIDACION_DASHBOARD_EMBARGOS.md |
| F1 Cliente bajo (0.508) | Desbalance 12:1 en datos | Subdetecci√≥n de clientes | INFORME_VALIDACION_DASHBOARD_PREDICCIONES.md |

### 9.3. Extensiones propuestas para monograf√≠a

#### Bloque 1: Normalizaci√≥n investigativa (impacto directo en m√©tricas)

| # | Propuesta | T√©cnica espec√≠fica | Beneficio esperado |
|---|-----------|-------------------|-------------------|
| 1 | Estandarizaci√≥n previa | z-score por entidad, winsorizaci√≥n P5-P95 | Reducir RMSE 20-30% |
| 2 | Evaluaci√≥n comparativa | Test A/B con datos normalizados | Cuantificar mejora |
| 3 | Transformaci√≥n de residuos | Box-Cox para estabilizar varianza | Intervalos no truncados |

#### Bloque 2: Modelos avanzados (extensi√≥n de capacidades)

| # | Propuesta | T√©cnica espec√≠fica | Caso de uso |
|---|-----------|-------------------|------------|
| 4 | Detecci√≥n de anomal√≠as | Isolation Forest, LSTM-Autoencoder | Meses/bancos at√≠picos |
| 5 | Forecasting probabil√≠stico | Prophet con cuantiles, Bayesian Ridge | Distribuci√≥n completa |
| 6 | Clasificadores robustos | Focal loss, SMOTE, cost-sensitive | Clases raras (<100) |

#### Bloque 3: MLOps y gobernanza (escalabilidad)

| # | Propuesta | T√©cnica espec√≠fica | Beneficio |
|---|-----------|-------------------|----------|
| 7 | Versionado de modelos | MLflow, DVC | Trazabilidad completa |
| 8 | Monitoreo de drift | Evidently, Alibi Detect | Alertas de degradaci√≥n |
| 9 | API REST | FastAPI con swagger | Integraci√≥n CRM/legales |
| 10 | Reportes programados | Jinja2 + PDF | Automatizaci√≥n semanal |

#### Bloque 4: Experiencia de usuario (accesibilidad)

| # | Propuesta | T√©cnica espec√≠fica | Audiencia |
|---|-----------|-------------------|----------|
| 11 | Wizard de configuraci√≥n | Formulario paso a paso | Usuarios no t√©cnicos |
| 12 | Dashboard de calidad | DQ score, alertas | Administradores de datos |
| 13 | Modo accesibilidad | WCAG 2.1, alto contraste | Usuarios con discapacidad |

### 9.4. Contribuci√≥n acad√©mica

Este proyecto aporta al campo de **gesti√≥n de informaci√≥n con soporte de aprendizaje autom√°tico** en tres dimensiones:

1. **Metodol√≥gica**: pipeline reproducible ETL+ML con configuraci√≥n CLI extensible
2. **Pr√°ctica**: soluci√≥n desplegable en entornos corporativos sin infraestructura ML
3. **Did√°ctica**: tooltips, documentaci√≥n t√©cnica, y transparencia de m√©tricas para transferencia de conocimiento

Las l√≠neas investigativas propuestas consolidar√≠an el sistema como **plataforma de referencia** para anal√≠tica empresarial con IA, generando aportes publicables en normalizaci√≥n de datos financieros, forecasting de procesos legales, y democratizaci√≥n de ML en organizaciones no t√©cnicas.

---

## 10. Referencias a documentaci√≥n t√©cnica complementaria

- `INFORME_VALIDACION_MODELO_ML.md`: pipeline predictivo, arquitectura dual validaci√≥n/pron√≥stico, m√©tricas actuales, impacto normalizaci√≥n pendiente, recomendaciones investigativas
- `INFORME_VALIDACION_DASHBOARD_EMBARGOS.md`: dashboard exploratorio, caracterizaci√≥n dataset, funcionamiento interno, hallazgos con datos no normalizados, l√≠neas de mejora
- `INFORME_VALIDACION_DASHBOARD_PREDICCIONES.md`: dashboard de pron√≥sticos, arquitectura carga, evidencias testing, limitaciones intervalos, propuestas visualizaci√≥n calidad
- `ANALISIS_COLUMNAS.md`: clasificaci√≥n campos por relevancia funcional
- `HISTORIAL_DE_CAMBIOS_Y_MEJORAS.md`: log evolutivo del proyecto

---

## Anexo A: Dependencias y versiones

### A.1. Dependencias Python (`requirements.txt`)

| Paquete | Prop√≥sito | Versi√≥n recomendada |
|---------|-----------|---------------------|
| `streamlit` | Framework de dashboards web | ‚â•1.28.0 |
| `pandas` | Manipulaci√≥n de datos tabulares | ‚â•2.0.0 |
| `numpy` | Operaciones num√©ricas | ‚â•1.24.0 |
| `plotly` | Gr√°ficos interactivos | ‚â•5.15.0 |
| `scikit-learn` | Preprocesamiento ML | ‚â•1.3.0 |
| `xgboost` | Algoritmos gradient boosting | ‚â•2.0.0 |
| `openpyxl` | Exportaci√≥n Excel | ‚â•3.1.0 |

**Instalaci√≥n**:
```bash
pip install -r requirements.txt
```

### A.2. Herramientas de construcci√≥n

| Herramienta | Prop√≥sito | Archivo de configuraci√≥n |
|-------------|-----------|--------------------------|
| PyInstaller | Empaquetado ejecutable | `build_executable.py`, `DashboardEmbargos.spec` |
| Inno Setup | Instalador Windows | `installer_setup.iss` |

---

## Anexo B: Estructura de archivos del proyecto

```
practica-analisis-embargos/
‚îú‚îÄ‚îÄ üìä src/dashboards/                     # Dashboards Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_embargos.py              # 1,700+ l√≠neas - exploraci√≥n hist√≥rica
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_predicciones.py          # 1,450+ l√≠neas - pron√≥sticos + m√©tricas ML
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_styles.py                # CSS centralizado (paleta corporativa)
‚îÇ   ‚îî‚îÄ‚îÄ dashboard_tabs_futuro.py           # Componentes adicionales de tabs
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ src/pipeline_ml/                    # Pipeline de Machine Learning
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ procesar_modelo.py                 # 866 l√≠neas - ETL + entrenamiento + predicci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ modelos_ml_embargos.ipynb          # Notebook experimental (desarrollo)
‚îÇ
‚îú‚îÄ‚îÄ üéõÔ∏è src/orquestacion/                   # Orquestaci√≥n y utilidades
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ launcher.py                        # GUI Tkinter (hub principal, 1,500+ l√≠neas)
‚îÇ   ‚îî‚îÄ‚îÄ utils_csv.py                       # Abstracci√≥n de rutas (dev vs ejecutable)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ datos/                              # Datos generados (output)
‚îÇ   ‚îú‚îÄ‚îÄ embargos_consolidado_mensual.csv
‚îÇ   ‚îú‚îÄ‚îÄ predicciones_oficios_validacion.csv
‚îÇ   ‚îú‚îÄ‚îÄ predicciones_oficios_futuro.csv
‚îÇ   ‚îú‚îÄ‚îÄ predicciones_demandados_validacion.csv
‚îÇ   ‚îú‚îÄ‚îÄ predicciones_demandados_futuro.csv
‚îÇ   ‚îî‚îÄ‚îÄ resultados_clasificaciones.csv
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                              # Tests automatizados
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_dashboard_load.py             # Validaci√≥n carga CSV
‚îÇ   ‚îú‚îÄ‚îÄ test_matrices_load.py              # Deserializaci√≥n JSON
‚îÇ   ‚îî‚îÄ‚îÄ test_predicciones_futuras.py       # Pipeline completo
‚îÇ
‚îú‚îÄ‚îÄ üì¶ construccion/                       # Herramientas de construcci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ build_executable.py                # Script PyInstaller
‚îÇ   ‚îú‚îÄ‚îÄ DashboardEmbargos.spec             # Configuraci√≥n PyInstaller
‚îÇ   ‚îî‚îÄ‚îÄ installer_setup.iss                # Configuraci√≥n Inno Setup
‚îÇ
‚îú‚îÄ‚îÄ üìù docs/                               # Documentaci√≥n t√©cnica
‚îÇ   ‚îú‚îÄ‚îÄ INFORME_PROYECTO_DASHBOARD_EMBARGOS.md  # Este documento
‚îÇ   ‚îú‚îÄ‚îÄ ANALISIS_COLUMNAS.md
‚îÇ   ‚îú‚îÄ‚îÄ GUIA_CREAR_INSTALADOR.md
‚îÇ   ‚îî‚îÄ‚îÄ HISTORIAL_DE_CAMBIOS_Y_MEJORAS.md
‚îÇ
‚îú‚îÄ‚îÄ ob.ico                                 # Icono de la aplicaci√≥n
‚îú‚îÄ‚îÄ README.md                              # Gu√≠a r√°pida de uso
‚îî‚îÄ‚îÄ requirements.txt                       # Dependencias Python
```

---

## Anexo C: Glosario t√©cnico

| T√©rmino | Definici√≥n |
|---------|------------|
| **RMSE** | Root Mean Squared Error ‚Äî ra√≠z del error cuadr√°tico medio, penaliza errores grandes |
| **MAE** | Mean Absolute Error ‚Äî error absoluto medio, robusto a outliers |
| **F1-score** | Media arm√≥nica de precisi√≥n y recall, m√©trica balanceada para clasificaci√≥n |
| **Lag** | Valor de una variable en un per√≠odo anterior (ej: `oficios_lag1` = oficios mes anterior) |
| **MA** | Moving Average ‚Äî media m√≥vil de N per√≠odos anteriores |
| **XGBoost** | eXtreme Gradient Boosting ‚Äî algoritmo de gradient boosting optimizado |
| **Poisson** | Distribuci√≥n de probabilidad para conteos no negativos |
| **scale_pos_weight** | Ponderaci√≥n para clases positivas en clasificaci√≥n desbalanceada |
| **Streamlit** | Framework Python para crear aplicaciones web de datos |
| **PyInstaller** | Herramienta para empaquetar Python en ejecutables standalone |
| **Inno Setup** | Herramienta para crear instaladores Windows |

---

*Documento actualizado: 2025-12-13*
*Versi√≥n del sistema: 2.2*
*Autor: Sistema de An√°lisis Predictivo de Embargos Bancarios*
